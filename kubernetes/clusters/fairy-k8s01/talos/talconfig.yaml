---
clusterName: fairy-k8s01
talosVersion: ${TALOS_VERSION}
kubernetesVersion: ${KUBERNETES_VERSION}
endpoint: https://192.168.102.30:6443
domain: cluster.local
allowSchedulingOnMasters: true
clusterPodNets:
  - 10.244.0.0/16
  - fd2b:ec92:e232::/48
clusterSvcNets:
  - 10.96.0.0/12
  - fd2b:ec92:e230:1::/112
cniConfig:
  name: none

nodes:
  - hostname: fairy-compute01
    ipAddress: 192.168.102.17
    controlPlane: true
    installDisk: /dev/sda

    machineSpec: &compute01-machineSpec
      mode: metal
      arch: amd64
      useUKI: true
      secureboot: true
    schematic: &compute01-schematic
      customization:
        systemExtensions:
          officialExtensions:
            - siderolabs/lldpd
            - siderolabs/i915
            - siderolabs/intel-ucode
            - siderolabs/mei
    extensionServices:
      - &compute01-lldp-extension
        name: lldpd
        configFiles:
          - mountPath: /usr/local/etc/lldpd/lldpd.conf
            content: |
              configure lldp portidsubtype ifname
              unconfigure lldp management-addresses-advertisements
              unconfigure lldp capabilities-advertisements
              configure system description "Talos Node"

    networkInterfaces:
      - &compute01-br0
        interface: br0
        bridge:
          stp:
            enabled: true
          interfaces:
            - enp133s0f0np0
        addresses:
          - 192.168.102.17/24
          - 2600:1700:541:fcc:9a03::a101/64
          - fd80:383:1a38::17/64
        routes:
          - network: 0.0.0.0/0
            gateway: 192.168.102.1
            metric: 1024
        vip:
          ip: 192.168.102.30
        vlans:
          - vlanId: 300
            mtu: 1500
            dhcp: false
        dhcp: false
        mtu: 9000
      - &compute01-nic01
        interface: enp133s0f0np0
        dhcp: false
        mtu: 9000
    extraManifests:
      - ./watchdog.yaml

  - hostname: fairy-compute02
    ipAddress: 192.168.102.18
    controlPlane: true
    installDisk: /dev/sda
    networkInterfaces:
      - <<: *compute01-br0
        addresses:
          - 192.168.102.18/24
          - 2600:1700:541:fcc:9a03::a102/64
          - fd80:383:1a38::18/64
      - <<: *compute01-nic01
    machineSpec: *compute01-machineSpec
    schematic: *compute01-schematic
    extensionServices:
      - <<: *compute01-lldp-extension
    extraManifests:
      - ./watchdog.yaml

  - hostname: fairy-compute03
    ipAddress: 192.168.102.19
    controlPlane: true
    installDisk: /dev/sda
    networkInterfaces:
      - <<: *compute01-br0
        addresses:
          - 192.168.102.19/24
          - 2600:1700:541:fcc:9a03::a103/64
          - fd80:383:1a38::19/64
      - <<: *compute01-nic01
    machineSpec: *compute01-machineSpec
    schematic: *compute01-schematic
    extensionServices:
      - <<: *compute01-lldp-extension
    extraManifests:
      - ./watchdog.yaml

controlPlane:
  nodeLabels: {}
  patches:
    # Cluster configuration
    - |-
      cluster:
        etcd:
          advertisedSubnets:
            - 192.168.102.0/24
          extraArgs:
            listen-metrics-urls: "http://0.0.0.0:2381"
        controllerManager:
          extraArgs:
            bind-address: 0.0.0.0
            node-cidr-mask-size-ipv6: 64
        scheduler:
          extraArgs:
            bind-address: 0.0.0.0
        proxy:
          disabled: true

    # Disable search domain everywhere
    - &disableSearchDomainPatch |-
      machine:
        network:
          disableSearchDomain: true

    # Set nameserver
    - &nameServersPatch |-
      machine:
        network:
          nameservers:
            - 1.1.1.1
            - 1.0.0.1

    # Enable K8s Talos API Access
    - |-
      machine:
        features:
          kubernetesTalosAPIAccess:
            enabled: true
            allowedRoles:
              - os:reader
              - os:admin
            allowedKubernetesNamespaces:
              - actions-runner-system
              - system-upgrade

    # Machine patches to apply to all nodes
    - &machinePatches |
      machine:
        features:
          # Configures host DNS caching resolver.
          hostDNS:
            enabled: true
            # Cilium update "broke" this so disabling it
            # * https://github.com/cilium/cilium/issues/35153
            # * https://github.com/siderolabs/talos/pull/9200
            forwardKubeDNSToHost: false
            resolveMemberNames: true
        # Configure containerd for spegel
        files:
          - op: create
            path: /etc/cri/conf.d/20-customization.part
            content: |
              [plugins."io.containerd.cri.v1.images"]
                discard_unpacked_layers = false
        sysctls:
          fs.inotify.max_user_watches: 1048576   # Watchdog
          fs.inotify.max_user_instances: 8192    # Watchdog
          net.core.default_qdisc: fq             # 10Gb/s
          net.core.rmem_max: 67108864            # 10Gb/s | Cloudflared / QUIC
          net.core.wmem_max: 67108864            # 10Gb/s | Cloudflared / QUIC
          net.ipv4.tcp_congestion_control: bbr   # 10Gb/s
          net.ipv4.tcp_fastopen: 3               # Send and accept data in the opening SYN packet
          net.ipv4.tcp_mtu_probing: 1            # 10Gb/s | Jumbo frames
          net.ipv4.tcp_rmem: 4096 87380 33554432 # 10Gb/s
          net.ipv4.tcp_wmem: 4096 65536 33554432 # 10Gb/s
          net.ipv4.tcp_window_scaling: 1         # 10Gb/s
          sunrpc.tcp_slot_table_entries: 128     # 10Gb/s | NFS
          sunrpc.tcp_max_slot_table_entries: 128 # 10Gb/s | NFS
          user.max_user_namespaces: 11255        # User Namespaces
          vm.nr_hugepages: 1024                  # PostgreSQL
        install:
          bootloader: true
          wipe: true
        systemDiskEncryption:
          ephemeral: &fde
            provider: luks2
            keys:
              - slot: 0
                tpm: {}
          state: *fde
        kubelet:
          nodeIP:
            validSubnets:
            - 192.168.102.0/24
            - "fd80:0383:1a38::/64"
          extraArgs: {}
          extraConfig:
            # Let IPv6 RAs through on 'net1' for thread announcements getting to HA additional NIC
            allowedUnsafeSysctls:
              - net.ipv6.conf.net1.accept_ra_rt_info_max_plen
            # Make image cleanup more aggressive
            imageMaximumGCAge: 168h # One week
            imageGCHighThresholdPercent: 50 # Default is 85%
            imageGCLowThresholdPercent: 20  # Default is 80%
            # Equivalent of `rotate-server-certificates` arg, for one less thing
            serverTLSBootstrap: true
        time:
          servers:
          - time.cloudflare.com # leave it as cloudflare but the router will hijack this and respond
    # bridge mac address hackery until https://github.com/siderolabs/talos/issues/10962 is releases
    # inspired by similiar from https://github.com/JJGadgets/Biohazard
    - &bridgeMacHackery |
      machine:
        pods:
          - apiVersion: v1
            kind: Pod
            metadata:
              name: &name "br-macaddr-hackery"
              namespace: "kube-system"
            spec:
              hostNetwork: true
              hostPID: true
              restartPolicy: OnFailure
              containers:
                - &ct
                  name: bridge-mac-set
                  image: "alpine:latest"
                  command: ["/bin/sh", "-c"]
                  args:
                    - |
                      duration=600
                      endTime=$(( $(date +%s) + duration ))
                      while [ $(date +%s) -lt $$endTime ]; do
                        for br in $(brctl show | awk '!/bridge name/' | cut -f1); do
                          ip link show dev $$br
                          ip link set $$br address $(brctl showmacs $$br | grep "0.00" | grep "  1" | grep "yes" | head -n 1 | cut -f2)
                          ip link show dev $$br
                        done
                        sleep 5
                      done
                  securityContext:
                    privileged: true
                  resources:
                    requests:
                      cpu: 0m
                      memory: 5Mi
                    limits:
                      cpu: 100m
                      memory: 64Mi
worker:
  patches:
    - *disableSearchDomainPatch
    - *nameServersPatch
    - *machinePatches
    - *bridgeMacHackery
