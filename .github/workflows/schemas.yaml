---
# yaml-language-server: $schema=https://json.schemastore.org/github-workflow.json
name: Schemas

on:
  workflow_dispatch:
  schedule:
    - cron: 0 0 * * *
  push:
    branches:
      - main
    paths:
      - .github/workflows/schemas.yaml
      - .github/workflows/schemas-extract.yaml

permissions:
  contents: read

jobs:
  clusters:
    name: Schemas - Cluster List
    runs-on: ubuntu-latest
    outputs:
      cluster-list: ${{ steps.list.outputs.clusters }}
    steps:
      - uses: actions/checkout@8e8c483db84b4bee98b60c0593521ed34d9990e8 # v6.0.1
      - id: list
        name: Get Cluster List
        working-directory: ./kubernetes/clusters
        run: |
          echo "clusters=$(ls -d * | jq --raw-input --slurp --compact-output 'split("\n")[:-1]')" >> ${GITHUB_OUTPUT}

  extract:
    needs: clusters
    name: Schemas - Extract
    strategy:
      matrix:
        cluster: ${{ fromJSON(needs.clusters.outputs.cluster-list) }}
      fail-fast: false
    uses: ./.github/workflows/schemas-extract.yaml
    with:
      cluster: ${{ matrix.cluster }}
      runner: ${{ matrix.cluster }}-infra-runner

  merge:
    needs: [clusters, extract]
    name: Schemas - Merge and Publish
    runs-on: ubuntu-latest
    permissions:
      contents: read
      packages: write
    steps:
      - name: Checkout
        uses: actions/checkout@8e8c483db84b4bee98b60c0593521ed34d9990e8 # v6.0.1
        with:
          persist-credentials: false

      - name: Download All Schema Artifacts
        uses: actions/download-artifact@37930b1c2abaa49bbe596cd826c3c89aef350131 # v7.0.0
        with:
          pattern: schemas-*
          path: merged-schemas

      - name: Merge Schemas
        run: |
          # Create the target directory
          mkdir -p crdSchemas

          # Copy all schemas from all clusters, preserving directory structure
          # When merge-multiple is true, artifacts are in cluster-specific subdirectories
          # (e.g., merged-schemas/schemas-cluster1/path/to/schema.json)
          # We need to strip the cluster-specific prefix and preserve the rest of the path
          find merged-schemas -type f | while read -r file; do
            # Get the relative path from merged-schemas, stripping the cluster-specific directory
            # e.g., merged-schemas/schemas-cluster1/path/to/schema.json -> path/to/schema.json
            rel_path="${file#merged-schemas/*/}"
            # Create the target directory structure
            target_file="crdSchemas/$rel_path"
            mkdir -p "$(dirname "$target_file")"
            # Copy the file, overwriting if it exists (last cluster wins)
            cp "$file" "$target_file"
          done

          # Count merged schemas
          schema_count=$(find crdSchemas -type f | wc -l)
          echo "Merged $schema_count schema files from all clusters"

      - name: Publish Schemas
        run: |
          BUCKET_NAME="${{ secrets.K8S_SCHEMAS_BUCKET_NAME }}"
          ENDPOINT_URL="${{ secrets.K8S_SCHEMAS_ENDPOINT_URL }}"
          aws s3 sync crdSchemas/ s3://$BUCKET_NAME/ \
            --endpoint-url="$ENDPOINT_URL" \
            --delete
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.K8S_SCHEMAS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.K8S_SCHEMAS_SECRET_ACCESS_KEY }}
          AWS_DEFAULT_REGION: auto

  success:
    if: ${{ !cancelled() }}
    needs: [extract, merge]
    name: Schemas - Success
    runs-on: ubuntu-latest
    steps:
      - name: Any jobs failed?
        if: ${{ contains(needs.*.result, 'failure') }}
        run: exit 1

      - name: All jobs passed or skipped?
        if: ${{ !(contains(needs.*.result, 'failure')) }}
        run: echo "All jobs passed or skipped" && echo "${{ toJSON(needs.*.result) }}"
